{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy\n",
    "\n",
    "from become_yukarin.config.config import create_from_json as create_config\n",
    "from become_yukarin.config.sr_config import create_from_json as create_sr_config\n",
    "from become_yukarin.dataset.dataset import AcousticFeatureProcess\n",
    "from become_yukarin.dataset.dataset import WaveFileLoadProcess\n",
    "from become_yukarin.param import Param\n",
    "from become_yukarin import SuperResolution\n",
    "from become_yukarin import AcousticConverter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('/mnt/dwango/hiroshiba/become-yukarin/harvest-innoise03/predictor_1290000.npz')\n",
    "config_path = Path('/mnt/dwango/hiroshiba/become-yukarin/harvest-innoise03/config.json')\n",
    "config = create_config(config_path)\n",
    "voice_changer = AcousticConverter(config, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('/mnt/dwango/hiroshiba/become-yukarin/sr-blur01/predictor_35000.npz')\n",
    "config_path = Path('/mnt/dwango/hiroshiba/become-yukarin/sr-blur01/config.json')\n",
    "sr_config = create_sr_config(config_path)\n",
    "super_resolution = SuperResolution(sr_config, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = './test_data/test-deep-learning-yuduki-yukari.wav'\n",
    "w_in = voice_changer._wave_process(str(p))\n",
    "f_in = voice_changer._feature_process(w_in)\n",
    "f_low = voice_changer.convert_to_feature(f_in)\n",
    "s_high = super_resolution.convert(f_low.spectrogram.astype(numpy.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[18, 4])\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(numpy.log(f_low.spectrogram).T, aspect='auto', origin='reverse')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(numpy.log(s_high).T, aspect='auto', origin='reverse')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = sr_config.dataset.param.voice_param.sample_rate\n",
    "wave = super_resolution(s_high, acoustic_feature=f_low, sampling_rate=rate)\n",
    "Audio(data=wave.wave, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
